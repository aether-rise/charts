replicaCount: 1

proxyRouter:
  image:
    repository: ghcr.io/aether-rise/proxy
    tag: "test-latest"
    pullPolicy: IfNotPresent
  env:
    WALLET_PRIVATE_KEY: "YOUR_PRIVATE_KEY" # Private Key from your Wallet as Consumer or Provider (needed for the proxy-router to sign transactions)
    ETH_NODE_ADDRESS: "wss://arb-sepolia.g.alchemy.com/v2/YOUR_ALCHEMY_ID" # Recommend using your own private ETH Node Address for better performance (via Alchemy or Infura)
    ETH_NODE_CHAIN_ID: 421614 # Testnet Chain ID
    DIAMOND_CONTRACT_ADDRESS: "0xb8C55cD613af947E73E262F0d3C54b7211Af16CF" # as of 10/30/2024
    MOR_TOKEN_ADDRESS: "0x34a285a1b1c166420df5b6630132542923b5b27e" # as of 10/30/2024

    WEB_ADDRESS: "0.0.0.0:8082" # Change to your desired port that your Proxy-router API (Swagger should be listening on)
    WEB_PUBLIC_URL: "localhost:8082" # Change to your desired port should match WEB_ADDRESS port number
    OPENAI_BASE_URL: "http://ollama:11434/v1" # Change to your OpenAI API port for local model

    PROVIDER_ALLOW_LIST: "" #Comma separated ProviderID list eg: 0x2736848ba8BfC010C845A3c95B567c5979E4C997,0x32c086D54b7CfddBEBF68390B0BA2fd597142E1C
    PROXY_ADDRESS: "0.0.0.0:3333"
    PROXY_STORAGE_PATH: "./data/"
    PROXY_STORE_CHAT_CONTEXT: "true"

    MODELS_CONFIG_PATH: "/app/models-config.json"
    ENVIRONMENT: "development"
    ETH_NODE_LEGACY_TX: "false"
    EXPLORER_API_URL: "https://api-sepolia.arbiscan.io/api"
    LOG_COLOR: "true"
    LOG_FOLDER_PATH: ""
    LOG_LEVEL_APP: "info"
    LOG_LEVEL_CONNECTION: "info"
    LOG_LEVEL_PROXY: "info"
    LOG_LEVEL_SCHEDULER: "info"
    OPENAI_API_KEY: "" #optional

    SYS_ENABLE: "false"
    SYS_LOCAL_PORT_RANGE: "1024 65535"
    SYS_NET_DEV_MAX_BACKLOG: 100000
    SYS_RLIMIT_HARD: 524288
    SYS_RLIMIT_SOFT: 524288
    SYS_SOMAXCONN: 100000
    SYS_TCP_MAX_SYN_BACKLOG: 100000
  ports:
    - 8080
    - 8082
    - 3333
  volumes:
    logs: /app/logs
    goPkgMod: /go/pkg/mod
  service:
    type: LoadBalancer  # Set to LoadBalancer for external access, or ClusterIP for internal
  configMap:
    modelsconfig: "{ \"0x6a4813e866a48da528c533e706344ea853a1d3f21e37b4c8e7ffd5ff25772024\": { \"modelName\": \"llama2\", \"apiType\": \"openai\", \"concurrentSlots\": 10, \"capacityPolicy\": \"idle_timeout\", \"apiUrl\": \"http://ollama:11434/v1\" } }"


ollama:
  image:
    repository: ollama/ollama
    tag: "latest"
    pullPolicy: IfNotPresent
  env:
    OLLAMA_NUM_PARALLEL: "4"
  ports:
    - 11434
  resources:
    limits:
      gpu: 1
  volumes:
    config: /root/.ollama
    startupScript: /docker-compose-startup.sh
  readinessProbe:
    path: /
    port: 11434
    initialDelaySeconds: 10
    periodSeconds: 5
